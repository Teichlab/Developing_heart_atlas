{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "comic-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import rc_context\n",
    "import bbknn\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import rpy2\n",
    "import anndata\n",
    "from datetime import date\n",
    "from scipy.stats import binom_test\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "# YYYY-MM-DD\n",
    "today = date.today()\n",
    "today = today.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-cameroon",
   "metadata": {},
   "source": [
    "# Read in peaks matrix and tidy it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "revolutionary-packing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:09:29:...reading peak file...takes 5 mins...\n",
      "21:14:24:...done.\n",
      "CPU times: user 4min 46s, sys: 7.1 s, total: 4min 53s\n",
      "Wall time: 4min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "    \n",
    "print(f'{current_time}:...reading peak file...takes 5 mins...')\n",
    "peaks=pd.read_csv('/nfs/team205/heart/anndata_objects/Foetal/multiome_ATAC/ArchR/project_output/PeakMatrix/Foetal_celltype-by-Peak.csv')\n",
    "    \n",
    "peaks.columns = peaks.columns.str.replace('Unnamed: 0', 'fine_grain')\n",
    "peaks=peaks.set_index(peaks['fine_grain'])\n",
    "peaks=peaks.drop(columns=['fine_grain'])\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(f'{current_time}:...done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ranking-teacher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.06 s, sys: 136 ms, total: 5.2 s\n",
      "Wall time: 5.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>peak_window</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peak</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chr1:794775_795275</th>\n",
       "      <td>chr1</td>\n",
       "      <td>794775_795275</td>\n",
       "      <td>794775</td>\n",
       "      <td>795275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:817100_817600</th>\n",
       "      <td>chr1</td>\n",
       "      <td>817100_817600</td>\n",
       "      <td>817100</td>\n",
       "      <td>817600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:817796_818296</th>\n",
       "      <td>chr1</td>\n",
       "      <td>817796_818296</td>\n",
       "      <td>817796</td>\n",
       "      <td>818296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:818511_819011</th>\n",
       "      <td>chr1</td>\n",
       "      <td>818511_819011</td>\n",
       "      <td>818511</td>\n",
       "      <td>819011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   chrom    peak_window   start     end\n",
       "peak                                                   \n",
       "chr1:794775_795275  chr1  794775_795275  794775  795275\n",
       "chr1:817100_817600  chr1  817100_817600  817100  817600\n",
       "chr1:817796_818296  chr1  817796_818296  817796  818296\n",
       "chr1:818511_819011  chr1  818511_819011  818511  819011"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "all_peaks=pd.DataFrame(peaks.columns, columns=['peak'])\n",
    "all_peaks['chrom']=all_peaks['peak'].str.split(':',expand=True)[0]\n",
    "all_peaks['peak_window']=all_peaks['peak'].str.split(':',expand=True)[1]\n",
    "all_peaks['start']=all_peaks['peak_window'].str.split('_',expand=True)[0].astype(int)\n",
    "all_peaks['end']=all_peaks['peak_window'].str.split('_',expand=True)[1].astype(int)\n",
    "all_peaks=all_peaks.set_index(['peak'])\n",
    "all_peaks.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-economics",
   "metadata": {},
   "source": [
    "# Set parameters for subsequent analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-watts",
   "metadata": {},
   "source": [
    "### Set Cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "strange-phone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "# get list of celltypes for subsequent analyses\n",
    "cell_types=peaks.index.unique().tolist()\n",
    "\n",
    "# remove celltypes not for analysis\n",
    "cell_types.remove('Platelets')\n",
    "cell_types.remove('VentricularCardiomyocytesCycling')\n",
    "cell_types.remove('AtrialCardiomyocytesCycling')\n",
    "\n",
    "#cell_types=cell_types[25:27] # reduced while developing\n",
    "\n",
    "print(len(cell_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-banner",
   "metadata": {},
   "source": [
    "### Set n_permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "caring-gateway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Set number of permutations\n",
    "n_permutations=1000 # reduced while developing\n",
    "print(n_permutations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-lemon",
   "metadata": {},
   "source": [
    "### Set threshold for binarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adjusted-conflict",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0p1\n"
     ]
    }
   ],
   "source": [
    "# Set threshold for binarisation\n",
    "threshold=0.1\n",
    "threshold_for_filename=str(threshold).replace('.','p')\n",
    "print(threshold_for_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-chile",
   "metadata": {},
   "source": [
    "# Prepare manually curated CHD gwas SNP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually collected list of SNPS which as signifcant at the genome wide level for a variety of CHD traits\n",
    "\n",
    "snps=pd.read_csv('/nfs/team205/heart/CHD_GWAS/chd_gwas_SNPs.csv').sort_values('simplified_classification')\n",
    "snps.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "placed-sperm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.27 s, sys: 44.1 ms, total: 2.32 s\n",
      "Wall time: 30.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Use Ensembl APU to add chromosomal position of each of the SNPs\n",
    "\n",
    "pos=[]\n",
    "chrom=[]\n",
    "\n",
    "\n",
    "for snp in range(len(snps['SNP'])):\n",
    "    server = \"https://rest.ensembl.org\"\n",
    "    ext = f\"/variation/human/{snps['SNP'][snp]}?\"\n",
    "    r = requests.get(server+ext, headers={ \"Content-Type\" : \"application/json\"})\n",
    "    decoded = r.json()\n",
    "    if len(decoded)>0 and \"mappings\" in decoded:\n",
    "        pos.append(decoded['mappings'][0]['start'])\n",
    "        chrom.append(decoded['mappings'][0]['seq_region_name'])\n",
    "snps['pos']=pos\n",
    "snps['chrom']=chrom\n",
    "snps.set_index('SNP',inplace=True)\n",
    "snps.to_csv('/nfs/team205/heart/CHD_GWAS/chd_gwas_SNPs_with_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fleet-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes=snps.simplified_classification.unique().tolist()\n",
    "for phenotype in phenotypes:\n",
    "    tmp=snps[snps['simplified_classification']==phenotype]\n",
    "    tmp.to_csv(f'/nfs/team205/heart/CHD_GWAS/chd_gwas_SNPs_with_pos-{phenotype}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "actual-channels",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "      <th>simplified_classification</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>study</th>\n",
       "      <th>pos</th>\n",
       "      <th>chrom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rs76774446</td>\n",
       "      <td>vascular</td>\n",
       "      <td>thoracic vessels</td>\n",
       "      <td>Lahm2021</td>\n",
       "      <td>40807221</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rs143638934</td>\n",
       "      <td>vascular</td>\n",
       "      <td>TGA</td>\n",
       "      <td>Lahm2021</td>\n",
       "      <td>40922047</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rs149890280</td>\n",
       "      <td>vascular</td>\n",
       "      <td>TGA</td>\n",
       "      <td>Lahm2021</td>\n",
       "      <td>104604349</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rs150246290</td>\n",
       "      <td>vascular</td>\n",
       "      <td>TGA</td>\n",
       "      <td>Lahm2021</td>\n",
       "      <td>9320073</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rs77094733</td>\n",
       "      <td>vascular</td>\n",
       "      <td>TGA</td>\n",
       "      <td>Lahm2021</td>\n",
       "      <td>73601791</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rs117527287</td>\n",
       "      <td>vascular</td>\n",
       "      <td>thoracic vessels</td>\n",
       "      <td>Lahm2021</td>\n",
       "      <td>51868281</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rs11874</td>\n",
       "      <td>vascular</td>\n",
       "      <td>thoracic vessels</td>\n",
       "      <td>Lahm2021</td>\n",
       "      <td>80475711</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rs17677363</td>\n",
       "      <td>vascular</td>\n",
       "      <td>thoracic vessels</td>\n",
       "      <td>Lahm2021</td>\n",
       "      <td>52539853</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rs148563140</td>\n",
       "      <td>vascular</td>\n",
       "      <td>TGA</td>\n",
       "      <td>Lahm2021</td>\n",
       "      <td>44161476</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rs149467721</td>\n",
       "      <td>vascular</td>\n",
       "      <td>TGA</td>\n",
       "      <td>Lahm2021</td>\n",
       "      <td>115946361</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SNP simplified_classification         phenotype     study  \\\n",
       "0   rs76774446                  vascular  thoracic vessels  Lahm2021   \n",
       "1  rs143638934                  vascular               TGA  Lahm2021   \n",
       "2  rs149890280                  vascular               TGA  Lahm2021   \n",
       "3  rs150246290                  vascular               TGA  Lahm2021   \n",
       "4   rs77094733                  vascular               TGA  Lahm2021   \n",
       "5  rs117527287                  vascular  thoracic vessels  Lahm2021   \n",
       "6      rs11874                  vascular  thoracic vessels  Lahm2021   \n",
       "7   rs17677363                  vascular  thoracic vessels  Lahm2021   \n",
       "8  rs148563140                  vascular               TGA  Lahm2021   \n",
       "9  rs149467721                  vascular               TGA  Lahm2021   \n",
       "\n",
       "         pos chrom  \n",
       "0   40807221    14  \n",
       "1   40922047    14  \n",
       "2  104604349     5  \n",
       "3    9320073     6  \n",
       "4   73601791     9  \n",
       "5   51868281     5  \n",
       "6   80475711     X  \n",
       "7   52539853    10  \n",
       "8   44161476     6  \n",
       "9  115946361     5  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snps_path='/nfs/team205/heart/CHD_GWAS/'\n",
    "\n",
    "files=os.listdir(snps_path)\n",
    "for phenotype in phenotypes:\n",
    "    file = [f for f in files if f\"{phenotype}\" in f]\n",
    "    file = str(file[0])\n",
    "    snps_df=pd.read_csv(f'{snps_path}{file}')\n",
    "snps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "empirical-digit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.4 ms, sys: 31 µs, total: 17.5 ms\n",
      "Wall time: 23.8 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_SNPs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simplified_classifcation</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>obstructive</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vascular</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LH</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOS</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>septal</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RH</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          n_SNPs\n",
       "simplified_classifcation        \n",
       "obstructive                   21\n",
       "vascular                      10\n",
       "LH                             8\n",
       "NOS                            8\n",
       "septal                         8\n",
       "RH                             1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# make a table of metadata about the SNP files\n",
    "md_simplified_classifcation=[]\n",
    "md_n_SNPs=[]\n",
    "\n",
    "snps_path='/nfs/team205/heart/CHD_GWAS/'\n",
    "\n",
    "files=os.listdir(snps_path)\n",
    "\n",
    "for phenotype in phenotypes:\n",
    "    file = [f for f in files if f\"{phenotype}\" in f]\n",
    "    file = str(file[0])\n",
    "    snps_df=pd.read_csv(f'{snps_path}{file}')\n",
    "    snps_df=snps_df.set_index('SNP')\n",
    "    md_simplified_classifcation.append(phenotype)\n",
    "    md_n_SNPs.append(len(snps_df))\n",
    "\n",
    "md_dict={\n",
    "    'simplified_classifcation':md_simplified_classifcation,\n",
    "    'n_SNPs':md_n_SNPs\n",
    "}\n",
    "\n",
    "SNP_md=pd.DataFrame(md_dict)\n",
    "\n",
    "SNP_md=SNP_md.set_index('simplified_classifcation')\n",
    "\n",
    "n_traits=len(phenotypes)\n",
    "\n",
    "SNP_md.sort_values('n_SNPs',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-blond",
   "metadata": {},
   "source": [
    "# Evaluate whether SNPs are found in peaks using the all_peaks file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "molecular-insertion",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir /nfs/team205/heart/CHD_GWAS/SNP_mapped_to_peaks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "automotive-inspiration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...a SNPs in peaks file for this set of traits is NOT found, making one now...\n",
      "22:01:20_LH:...evaluating for SNPs in peaks...\n",
      "22:01:27_NOS:...evaluating for SNPs in peaks...\n",
      "22:01:33_RH:...evaluating for SNPs in peaks...\n",
      "22:01:33_obstructive:...evaluating for SNPs in peaks...\n",
      "22:01:50_septal:...evaluating for SNPs in peaks...\n",
      "22:01:56_vascular:...evaluating for SNPs in peaks...\n",
      "CPU times: user 37.6 s, sys: 138 ms, total: 37.7 s\n",
      "Wall time: 38.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>peak_window</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>LH</th>\n",
       "      <th>NOS</th>\n",
       "      <th>RH</th>\n",
       "      <th>obstructive</th>\n",
       "      <th>septal</th>\n",
       "      <th>vascular</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peak</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chr1:794775_795275</th>\n",
       "      <td>chr1</td>\n",
       "      <td>794775_795275</td>\n",
       "      <td>794775</td>\n",
       "      <td>795275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:817100_817600</th>\n",
       "      <td>chr1</td>\n",
       "      <td>817100_817600</td>\n",
       "      <td>817100</td>\n",
       "      <td>817600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:817796_818296</th>\n",
       "      <td>chr1</td>\n",
       "      <td>817796_818296</td>\n",
       "      <td>817796</td>\n",
       "      <td>818296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:818511_819011</th>\n",
       "      <td>chr1</td>\n",
       "      <td>818511_819011</td>\n",
       "      <td>818511</td>\n",
       "      <td>819011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:820996_821496</th>\n",
       "      <td>chr1</td>\n",
       "      <td>820996_821496</td>\n",
       "      <td>820996</td>\n",
       "      <td>821496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:155768443_155768943</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155768443_155768943</td>\n",
       "      <td>155768443</td>\n",
       "      <td>155768943</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:155820075_155820575</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155820075_155820575</td>\n",
       "      <td>155820075</td>\n",
       "      <td>155820575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:155880511_155881011</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155880511_155881011</td>\n",
       "      <td>155880511</td>\n",
       "      <td>155881011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:155881078_155881578</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155881078_155881578</td>\n",
       "      <td>155881078</td>\n",
       "      <td>155881578</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:155972148_155972648</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155972148_155972648</td>\n",
       "      <td>155972148</td>\n",
       "      <td>155972648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>464498 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         chrom          peak_window      start        end  LH  \\\n",
       "peak                                                                            \n",
       "chr1:794775_795275        chr1        794775_795275     794775     795275   0   \n",
       "chr1:817100_817600        chr1        817100_817600     817100     817600   0   \n",
       "chr1:817796_818296        chr1        817796_818296     817796     818296   0   \n",
       "chr1:818511_819011        chr1        818511_819011     818511     819011   0   \n",
       "chr1:820996_821496        chr1        820996_821496     820996     821496   0   \n",
       "...                        ...                  ...        ...        ...  ..   \n",
       "chrX:155768443_155768943  chrX  155768443_155768943  155768443  155768943   0   \n",
       "chrX:155820075_155820575  chrX  155820075_155820575  155820075  155820575   0   \n",
       "chrX:155880511_155881011  chrX  155880511_155881011  155880511  155881011   0   \n",
       "chrX:155881078_155881578  chrX  155881078_155881578  155881078  155881578   0   \n",
       "chrX:155972148_155972648  chrX  155972148_155972648  155972148  155972648   0   \n",
       "\n",
       "                          NOS  RH  obstructive  septal  vascular  \n",
       "peak                                                              \n",
       "chr1:794775_795275          0   0            0       0         0  \n",
       "chr1:817100_817600          0   0            0       0         0  \n",
       "chr1:817796_818296          0   0            0       0         0  \n",
       "chr1:818511_819011          0   0            0       0         0  \n",
       "chr1:820996_821496          0   0            0       0         0  \n",
       "...                       ...  ..          ...     ...       ...  \n",
       "chrX:155768443_155768943    0   0            0       0         0  \n",
       "chrX:155820075_155820575    0   0            0       0         0  \n",
       "chrX:155880511_155881011    0   0            0       0         0  \n",
       "chrX:155881078_155881578    0   0            0       0         0  \n",
       "chrX:155972148_155972648    0   0            0       0         0  \n",
       "\n",
       "[464498 rows x 10 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Add on a column for each trait, indicating whether a SNP from that trait falls within a peak. This file varies with the which traits are assessed\n",
    "files=os.listdir(snps_path)\n",
    "\n",
    "if os.path.isfile(f'/nfs/team205/heart/CHD_GWAS/SNP_mapped_to_peaksall_peaks_with_SNPs_for_{n_traits}_traits_incremental.csv')==False:\n",
    "    print(f'...a SNPs in peaks file for this set of traits is NOT found, making one now...')\n",
    "    for phenotype in phenotypes:\n",
    "\n",
    "            file = [f for f in files if f\"{phenotype}\" in f]\n",
    "            file = str(file[0])\n",
    "\n",
    "            snps_df=pd.read_csv(f'{snps_path}{file}')\n",
    "            snps_df=snps_df.set_index('SNP')\n",
    "\n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%H:%M:%S\")\n",
    "            print(f'{current_time}_{phenotype}:...evaluating for SNPs in peaks...')\n",
    "\n",
    "            all_peaks[phenotype]=0\n",
    "            for snp in range(len(snps_df[\"chrom\"])): # This loop incrementally adds 1 if there is a SNP within a peak (open or closed)\n",
    "                all_peaks[phenotype][\n",
    "                    (all_peaks['chrom']==snps_df[\"chrom\"][snp])\n",
    "                    &\n",
    "                    (all_peaks['start'] <= snps_df['pos'][snp])\n",
    "                    &\n",
    "                    (all_peaks['end'] >= snps_df['pos'][snp])\n",
    "                ]+=1 # Adds one for each SNP which falls inside a peak\n",
    "    all_peaks.to_csv(f'/nfs/team205/heart/CHD_GWAS/SNP_mapped_to_peaksall_peaks_with_SNPs_for_{n_traits}_traits_incremental.csv')\n",
    "else:\n",
    "    all_peaks=pd.read_csv(f'/nfs/team205/heart/CHD_GWAS/SNP_mapped_to_peaksall_peaks_with_SNPs_for_{n_traits}_traits_incremental.csv',index_col='peak')\n",
    "    print(f'...SNPs in peaks file already exists, reading it in...')\n",
    "\n",
    "all_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-clear",
   "metadata": {},
   "source": [
    "# Make a table of peaks x cell for each cell type, binarise using a threshold, then make 1000 permutations, then overwrite the file"
   ]
  },
  {
   "cell_type": "raw",
   "id": "compressed-dressing",
   "metadata": {
    "tags": []
   },
   "source": [
    "# if you need to clear\n",
    "\n",
    "! rm -r /nfs/team205/heart/EBI_GWAS/binarised_permutation_matrices/*\n",
    "! mkdir /nfs/team205/heart/EBI_GWAS/binarised_permutation_matrices_joined/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "julian-dollar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT generating binarised matrix for VentricularConductionSystemDistal since it already exists\n",
      "NOT generating binarised matrix for DendriticCells since it already exists\n",
      "NOT generating binarised matrix for GreatVesselAdventitialFibroblasts since it already exists\n",
      "NOT generating binarised matrix for GlialCells since it already exists\n",
      "NOT generating binarised matrix for AtrialCardiomyocytesRight since it already exists\n",
      "NOT generating binarised matrix for ParasympatheticNeurons since it already exists\n",
      "NOT generating binarised matrix for CoronaryEndothelialCellsVenous since it already exists\n",
      "NOT generating binarised matrix for NeuronProgenitors since it already exists\n",
      "NOT generating binarised matrix for MastCells since it already exists\n",
      "NOT generating binarised matrix for ProBCells since it already exists\n",
      "NOT generating binarised matrix for LymphaticEndothelialCells since it already exists\n",
      "NOT generating binarised matrix for NaturalKillerCells since it already exists\n",
      "NOT generating binarised matrix for AtrioventricularNodeCardiomyocytes since it already exists\n",
      "NOT generating binarised matrix for ValveInterstitialCells since it already exists\n",
      "NOT generating binarised matrix for VentricularConductionSystemProximal since it already exists\n",
      "NOT generating binarised matrix for ValveEndothelialCells since it already exists\n",
      "NOT generating binarised matrix for MacrophagesLYVE1pos since it already exists\n",
      "NOT generating binarised matrix for InnateLymphoidCells since it already exists\n",
      "NOT generating binarised matrix for GreatVesselSmoothMuscleCells since it already exists\n",
      "NOT generating binarised matrix for EndocardialCells since it already exists\n",
      "NOT generating binarised matrix for Monocytes since it already exists\n",
      "NOT generating binarised matrix for CoronaryVesselAdventitialFibroblasts since it already exists\n",
      "NOT generating binarised matrix for MesothelialEpicardialCells since it already exists\n",
      "NOT generating binarised matrix for MyocardialInterstitialFibroblasts since it already exists\n",
      "NOT generating binarised matrix for CoronaryEndothelialCellsArterial since it already exists\n",
      "NOT generating binarised matrix for SympatheticNeurons since it already exists\n",
      "NOT generating binarised matrix for Cardiofibromyocytes since it already exists\n",
      "NOT generating binarised matrix for ChromaffinCells since it already exists\n",
      "NOT generating binarised matrix for SinoatrialNodeCardiomyocytes since it already exists\n",
      "NOT generating binarised matrix for Myofibroblasts since it already exists\n",
      "NOT generating binarised matrix for BCells since it already exists\n",
      "NOT generating binarised matrix for FibroblasticEpicardialCells since it already exists\n",
      "NOT generating binarised matrix for VentricularCardiomyocytesPRRX1pos since it already exists\n",
      "NOT generating binarised matrix for VentricularCardiomyocytesTrabeculated since it already exists\n",
      "NOT generating binarised matrix for CoronaryEndothelialCellsCapillary since it already exists\n",
      "NOT generating binarised matrix for EarlyGreatVesselCells since it already exists\n",
      "NOT generating binarised matrix for AtrialCardiomyocytesLeft since it already exists\n",
      "NOT generating binarised matrix for CoronarySmoothMuscleCells since it already exists\n",
      "NOT generating binarised matrix for MacrophagesCX3CR1pos since it already exists\n",
      "NOT generating binarised matrix for GlialCellProgenitors since it already exists\n",
      "NOT generating binarised matrix for GreatVesselEndothelialCells since it already exists\n",
      "NOT generating binarised matrix for VentricularCardiomyocytesCompact since it already exists\n",
      "NOT generating binarised matrix for CoronaryPericytes since it already exists\n",
      "NOT generating binarised matrix for TCells since it already exists\n",
      "finished\n",
      "CPU times: user 3.73 ms, sys: 27 µs, total: 3.76 ms\n",
      "Wall time: 91.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# makes cell x peak matrix, including 1000 permutations\n",
    "# NB the SNPs in peaks file needs is specific to the defined set of peaks, which will vary accoring to threshold for binarisation, so this all peaks file needs to be saved according to threshold used\n",
    "\n",
    "permutations=range(n_permutations)\n",
    "\n",
    "bin_mat_path='/nfs/team205/heart/EBI_GWAS/binarised_permutation_matrices/'\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    if os.path.isfile(f'{bin_mat_path}{cell_type}_{n_permutations}_permutations_bin_threshold_{threshold_for_filename}_matrix.csv') == False:\n",
    "\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        print(f'{current_time}...generating binarised matrix for {cell_type}...')\n",
    "\n",
    "        cell_df=pd.DataFrame(peaks.loc[cell_type])\n",
    "        cell_df['peak'] = cell_df.index\n",
    "        cell_df['chrom']=cell_df['peak'].str.split(':',expand=True)[0]\n",
    "        cell_df['peak_window']=cell_df['peak'].str.split(':',expand=True)[1]\n",
    "        cell_df['start']=cell_df['peak_window'].str.split('_',expand=True)[0].astype(int)\n",
    "        cell_df['end']=cell_df['peak_window'].str.split('_',expand=True)[1].astype(int)\n",
    "        cell_df[f'{cell_type}_binarised_real']=cell_df[cell_type].ge(threshold).astype(int)\n",
    "\n",
    "        for permutation in permutations:\n",
    "            cell_df[f'{cell_type}_binarised_permutation_{permutation}'] = np.random.permutation(cell_df[f'{cell_type}_binarised_real'])\n",
    "        cell_df=cell_df.filter(regex=cell_type+'_')\n",
    "        cell_df.to_csv(f'{bin_mat_path}{cell_type}_{n_permutations}_permutations_bin_threshold_{threshold_for_filename}_matrix.csv',index=True)\n",
    "    else:\n",
    "        print(f'NOT generating binarised matrix for {cell_type} since it already exists')\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-confirmation",
   "metadata": {},
   "source": [
    "# Read in Binarised Matrix for each cell type, join it to the all_peaks file which has trait info (binding on the index [peaks]), then save these joined binarised matrix files (now with added trait info) in a different directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-gospel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:06:29: VentricularConductionSystemDistal: making bin matrix with trait for this cell\n",
      "22:08:42: DendriticCells: making bin matrix with trait for this cell\n",
      "22:10:53: GreatVesselAdventitialFibroblasts: making bin matrix with trait for this cell\n",
      "22:13:03: GlialCells: making bin matrix with trait for this cell\n",
      "22:15:12: AtrialCardiomyocytesRight: making bin matrix with trait for this cell\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "joined_bin_mat_path='/nfs/team205/heart/CHD_GWAS/binarised_permutation_matrices_joined_incremental/'\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    if os.path.isfile(f'{joined_bin_mat_path}{cell_type}_{n_permutations}_permutations_bin_threshold_{threshold_for_filename}_matrix_joined.csv') == False:    \n",
    "        \n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(f'{current_time}: {cell_type}: making bin matrix with trait for this cell')\n",
    "\n",
    "        # read in binary matrices which have already been made\n",
    "        binarised_matrix=pd.read_csv(f'{bin_mat_path}{cell_type}_{n_permutations}_permutations_bin_threshold_{threshold_for_filename}_matrix.csv')\n",
    "\n",
    "        # tidy and add the columns we need\n",
    "        binarised_matrix.rename(columns = {'Unnamed: 0':'peak'}, inplace = True)\n",
    "        binarised_matrix=binarised_matrix.set_index(binarised_matrix.iloc[:,0])\n",
    "        binarised_matrix=binarised_matrix.drop(columns=['peak'])\n",
    "        \n",
    "        # add on the columns indicating whether SNPs are in peaks\n",
    "        binarised_matrix=binarised_matrix.join(all_peaks)\n",
    "\n",
    "        # save this modified binary matrix to a separate directory\n",
    "        binarised_matrix.to_csv(f'{joined_bin_mat_path}{cell_type}_{n_permutations}_permutations_bin_threshold_{threshold_for_filename}_matrix_joined.csv')\n",
    "    else:\n",
    "        print(f'NOT generating joined binarised matrix for {cell_type} since it already exists')\n",
    "\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-helen",
   "metadata": {},
   "source": [
    "# Calculate enrichment of cell types for different traits"
   ]
  },
  {
   "cell_type": "raw",
   "id": "another-language",
   "metadata": {},
   "source": [
    "# While developing\n",
    "cell_types=cell_types[0:10]\n",
    "print(cell_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Find the proportion of all peaks which are open in this celltype\n",
    "\n",
    "output_path='/nfs/team205/heart/EBI_GWAS/enrichment_output/'\n",
    "\n",
    "list_of_output_dfs=[]\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(f'...================================================================...') \n",
    "print(f'...{current_time}:STARTING')\n",
    "print(f'...================================================================...') \n",
    "\n",
    "# make some empty lists\n",
    "proportion_of_SNPs_found_in_celltype_specific_open_peaks=[]\n",
    "proportion_of_all_open_peaks_found_in_this_celltype=[]\n",
    "\n",
    "n_times_proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion=[]\n",
    "mean_proportions_of_SNPs_in_open_peaks=[]\n",
    "p_values=[]\n",
    "phenotype_list=[]\n",
    "cell_type_list=[]\n",
    "n_SNPs_list=[]\n",
    "\n",
    "cell_types_done=[]\n",
    "n_cell_types_total=len(cell_types)\n",
    "\n",
    "permutations=range(n_permutations)\n",
    "\n",
    "print('...evaluating '+str(len(phenotypes))+' traits, across '+str(len(cell_types))+' cell types...')\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    \n",
    "    cell_types_done.append(cell_type)\n",
    "    n_cell_types_done=len(cell_types_done)\n",
    "    n_cell_types_remaining=n_cell_types_total-n_cell_types_done\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(f'...================================================================...')    \n",
    "    print(f'...{current_time}: {n_cell_types_remaining+1} of {n_cell_types_total} cell types remaining. Reading binarised matrix for {cell_type}...')\n",
    "    print(f'...================================================================...') \n",
    "\n",
    "    cell_bin_mat=pd.read_csv(f'{joined_bin_mat_path}{cell_type}_{n_permutations}_permutations_bin_threshold_{threshold_for_filename}_matrix_joined.csv',index_col='peak')\n",
    "    \n",
    "    prop_bins_in_this_cell_type=(len(cell_bin_mat[cell_bin_mat[f'{cell_type}_binarised_real']==1]))/len(cell_bin_mat)\n",
    "            \n",
    "    \n",
    "    for phenotype in phenotypes:\n",
    "                \n",
    "        # grab some metadata\n",
    "        n_SNPs=SNP_md.loc[phenotype]['n_SNPs']\n",
    "        \n",
    "        # add columns which won't change until we run a new cell_type\n",
    "        proportion_of_all_open_peaks_found_in_this_celltype.append(prop_bins_in_this_cell_type)\n",
    "        cell_type_list.append(cell_type)\n",
    "\n",
    "        # add columns which won't change until we run a new phenotype\n",
    "        n_SNPs_list.append(n_SNPs)\n",
    "        phenotype_list.append(phenotype)\n",
    "        \n",
    "        # subset to just open regions for this cell type\n",
    "        # find the proportion of SNPs for this trait that lie within this cell types open peaks\n",
    "        observed_proportion=(cell_bin_mat[phenotype][cell_bin_mat[f'{cell_type}_binarised_real']==1].sum())/(cell_bin_mat[phenotype].sum())\n",
    "\n",
    "        proportion_of_SNPs_found_in_celltype_specific_open_peaks.append(observed_proportion)\n",
    "        \n",
    "        proportion_of_SNPs_found_in_permutations_of_celltype_specific_open_peaks=[]\n",
    "\n",
    "        for permutation in permutations:\n",
    "            proportion_of_SNPs_found_in_permutations_of_celltype_specific_open_peaks.append(cell_bin_mat[phenotype][cell_bin_mat[f'{cell_type}_binarised_permutation_{permutation}']==1].sum()/cell_bin_mat[phenotype].sum())\n",
    "\n",
    "        proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion = [i for i in proportion_of_SNPs_found_in_permutations_of_celltype_specific_open_peaks if i >= observed_proportion]\n",
    "        \n",
    "        n_times_proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion.append(len(proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion))\n",
    "\n",
    "        p_values.append(len(proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion)/len(permutations)) # p val is simply the proportion of null hypotheses 'observations' greater than the actual observed proportion\n",
    "\n",
    "        mean_proportions_of_SNPs_in_open_peaks.append(sum(proportion_of_SNPs_found_in_permutations_of_celltype_specific_open_peaks)/len(proportion_of_SNPs_found_in_permutations_of_celltype_specific_open_peaks))\n",
    "        \n",
    "        # Plot histograms for each cell type\n",
    "#        plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "#        plt.rcParams[\"figure.dpi\"] = 300\n",
    "\n",
    "#        plt.hist(proportion_of_SNPs_found_in_permutations_of_celltype_specific_open_peaks,\n",
    "#                 bins=100,color='red',\n",
    "#                 range=(0,1),\n",
    "#                 histtype='stepfilled',edgecolor='none')\n",
    "#        plt.axvline(x=observed_proportion, color='blue', linestyle='--')\n",
    "#        plt.legend(['null: proportion of SNPs falling in randomly shuffled OC regions','observed: proportion of SNPs falling cell-type specific OC regions'])\n",
    "#        plt.title('cell type: '+cell_type+', trait: '+phenotype+', phenotype: '+phenotype+', threshold for binarisation: '+threshold_for_filename)\n",
    "#        plt.savefig(f'{output_path}{phenotype}_{cell_type}_{threshold_for_filename}_SNP_enrichment.png')\n",
    "#        plt.clf() #clears the current plobt\n",
    "\n",
    "        \n",
    "output_dict={\n",
    "    'cell_type':cell_type_list,\n",
    "    'proportion_of_all_open_peaks_found_in_this_celltype':proportion_of_all_open_peaks_found_in_this_celltype,\n",
    "    'proportion_of_SNPs_found_in_celltype_specific_open_peaks':proportion_of_SNPs_found_in_celltype_specific_open_peaks,\n",
    "    'mean_proportions_of_SNPs_in_open_peaks':mean_proportions_of_SNPs_in_open_peaks,\n",
    "    'n_times_proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion':n_times_proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion,\n",
    "    'p_value':p_values,\n",
    "    'n_SNPs':n_SNPs_list,\n",
    "    'phenotype':phenotype_list}\n",
    "\n",
    "output_df=pd.DataFrame(output_dict)\n",
    "\n",
    "list_of_output_dfs.append(output_df)\n",
    "combined_output_df=pd.concat(list_of_output_dfs)\n",
    "combined_output_df=combined_output_df.sort_values(by=['phenotype'])\n",
    "combined_output_df=combined_output_df.set_index('cell_type')\n",
    "combined_output_df.to_csv(f'{output_path}{threshold_for_filename}_all_traits_summary.csv')\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(f'...================================================================...')    \n",
    "print(f'...{current_time}:FINSIHED')\n",
    "print(f'...================================================================...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-crystal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scanpy",
   "language": "python",
   "name": "scanpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
