{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "moved-minnesota",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/my-conda-envs/scanpy/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import rc_context\n",
    "import bbknn\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import rpy2\n",
    "import anndata\n",
    "from datetime import date\n",
    "from scipy.stats import binom_test\n",
    "from datetime import datetime\n",
    "\n",
    "# YYYY-MM-DD\n",
    "today = date.today()\n",
    "today = today.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-windsor",
   "metadata": {},
   "source": [
    "# Read in peaks matrix and tidy it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adverse-protein",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:47:13:...reading peak file...takes 5 mins...\n",
      "21:52:04:...done.\n",
      "CPU times: user 4min 40s, sys: 7.99 s, total: 4min 48s\n",
      "Wall time: 4min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "    \n",
    "print(f'{current_time}:...reading peak file...takes 5 mins...')\n",
    "peaks=pd.read_csv('/nfs/team205/heart/anndata_objects/Foetal/multiome_ATAC/ArchR/project_output/PeakMatrix/Foetal_celltype-by-Peak.csv')\n",
    "    \n",
    "peaks.columns = peaks.columns.str.replace('Unnamed: 0', 'fine_grain')\n",
    "peaks=peaks.set_index(peaks['fine_grain'])\n",
    "peaks=peaks.drop(columns=['fine_grain'])\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(f'{current_time}:...done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pretty-western",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.19 s, sys: 116 ms, total: 5.31 s\n",
      "Wall time: 5.31 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>peak_window</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peak</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chr1:794775_795275</th>\n",
       "      <td>chr1</td>\n",
       "      <td>794775_795275</td>\n",
       "      <td>794775</td>\n",
       "      <td>795275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:817100_817600</th>\n",
       "      <td>chr1</td>\n",
       "      <td>817100_817600</td>\n",
       "      <td>817100</td>\n",
       "      <td>817600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:817796_818296</th>\n",
       "      <td>chr1</td>\n",
       "      <td>817796_818296</td>\n",
       "      <td>817796</td>\n",
       "      <td>818296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:818511_819011</th>\n",
       "      <td>chr1</td>\n",
       "      <td>818511_819011</td>\n",
       "      <td>818511</td>\n",
       "      <td>819011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   chrom    peak_window   start     end\n",
       "peak                                                   \n",
       "chr1:794775_795275  chr1  794775_795275  794775  795275\n",
       "chr1:817100_817600  chr1  817100_817600  817100  817600\n",
       "chr1:817796_818296  chr1  817796_818296  817796  818296\n",
       "chr1:818511_819011  chr1  818511_819011  818511  819011"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "all_peaks=pd.DataFrame(peaks.columns, columns=['peak'])\n",
    "all_peaks['chrom']=all_peaks['peak'].str.split(':',expand=True)[0]\n",
    "all_peaks['peak_window']=all_peaks['peak'].str.split(':',expand=True)[1]\n",
    "all_peaks['start']=all_peaks['peak_window'].str.split('_',expand=True)[0].astype(int)\n",
    "all_peaks['end']=all_peaks['peak_window'].str.split('_',expand=True)[1].astype(int)\n",
    "all_peaks=all_peaks.set_index(['peak'])\n",
    "all_peaks.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-force",
   "metadata": {},
   "source": [
    "# Set parameters for subsequent analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-macintosh",
   "metadata": {},
   "source": [
    "### Set Cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "raised-copying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "# get list of celltypes for subsequent analyses\n",
    "cell_types=peaks.index.unique().tolist()\n",
    "\n",
    "# remove celltypes not for analysis\n",
    "cell_types.remove('Platelets')\n",
    "cell_types.remove('VentricularCardiomyocytesCycling')\n",
    "cell_types.remove('AtrialCardiomyocytesCycling')\n",
    "\n",
    "#cell_types=cell_types[25:27] # reduced while developing\n",
    "\n",
    "print(len(cell_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-breakfast",
   "metadata": {},
   "source": [
    "### Set n_permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "descending-chain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Set number of permutations\n",
    "n_permutations=1000 # reduced while developing\n",
    "print(n_permutations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-laptop",
   "metadata": {},
   "source": [
    "### Set threshold for binarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fitting-cambridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0p1\n"
     ]
    }
   ],
   "source": [
    "# Set threshold for binarisation\n",
    "threshold=0.1\n",
    "threshold_for_filename=str(threshold).replace('.','p')\n",
    "print(threshold_for_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-semiconductor",
   "metadata": {},
   "source": [
    "# Make some SNP table metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "awful-access",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 traits found. Removed 111 traits with fewer than 20 SNPs\n",
      "CPU times: user 770 ms, sys: 19.2 ms, total: 790 ms\n",
      "Wall time: 1.06 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>efo_term</th>\n",
       "      <th>n_SNPs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efo_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MONDO_0005090</th>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>3348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFO_0001645</th>\n",
       "      <td>coronary artery disease</td>\n",
       "      <td>1907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFO_0005763</th>\n",
       "      <td>pulse pressure measurement</td>\n",
       "      <td>1706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFO_0004761</th>\n",
       "      <td>uric acid measurement</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFO_0004682</th>\n",
       "      <td>QT interval</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFO_1001161</th>\n",
       "      <td>rheumatic heart disease</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFO_0005243</th>\n",
       "      <td>myeloperoxidase measurement</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFO_0005037</th>\n",
       "      <td>aortic root size</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFO_0004507</th>\n",
       "      <td>D dimer measurement</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFO_0005094</th>\n",
       "      <td>P wave duration</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  efo_term  n_SNPs\n",
       "efo_id                                            \n",
       "MONDO_0005090                schizophrenia    3348\n",
       "EFO_0001645        coronary artery disease    1907\n",
       "EFO_0005763     pulse pressure measurement    1706\n",
       "EFO_0004761          uric acid measurement     633\n",
       "EFO_0004682                    QT interval     592\n",
       "...                                    ...     ...\n",
       "EFO_1001161        rheumatic heart disease      21\n",
       "EFO_0005243    myeloperoxidase measurement      21\n",
       "EFO_0005037               aortic root size      21\n",
       "EFO_0004507            D dimer measurement      20\n",
       "EFO_0005094                P wave duration      20\n",
       "\n",
       "[89 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# make a table of metadata about the SNP files\n",
    "md_efo_ids=[]\n",
    "md_efo_terms=[]\n",
    "md_n_SNPs=[]\n",
    "pointlessly_small_n_SNPs=[]\n",
    "\n",
    "snps_path='/nfs/team205/heart/EBI_GWAS/index_snps/'\n",
    "\n",
    "pointlessly_small_threshold=20\n",
    "\n",
    "files=os.listdir(snps_path)\n",
    "\n",
    "efo_ids=[]\n",
    "\n",
    "for file in range(len(files)):\n",
    "    efo_ids.append(str(files[file].split(\"_\")[0])+'_'+str(files[file].split(\"_\")[1]))\n",
    "\n",
    "for efo_id in efo_ids:\n",
    "    file = [f for f in files if f\"{efo_id}\" in f]\n",
    "    file = str(file[0])\n",
    "    snps_df=pd.read_csv(f'{snps_path}{file}')\n",
    "    snps_df=snps_df.set_index('variant_id')\n",
    "    snps_df=snps_df.dropna(axis=0) # remove any rows containign NaNs\n",
    "    if len(snps_df)<pointlessly_small_threshold:\n",
    "        pointlessly_small_n_SNPs.append(efo_id)\n",
    "    else:\n",
    "        snps_df[\"chrom\"] = snps_df[\"chromosome_name\"].apply(lambda x: 'chr'+str(x)).str.split('.',expand=True)[0] # creates a new 'chrom' column and should work even for X or M chromosomes\n",
    "        md_efo_ids.append(snps_df['efo_id'][0])\n",
    "        md_efo_terms.append(snps_df['efo_term'][0])\n",
    "        md_n_SNPs.append(len(snps_df))\n",
    "\n",
    "md_dict={\n",
    "    'efo_id':md_efo_ids,\n",
    "    'efo_term':md_efo_terms,\n",
    "    'n_SNPs':md_n_SNPs\n",
    "}\n",
    "\n",
    "# re-define efo_id list removing the really short ones.\n",
    "efo_ids_not_too_small= [efo_id for efo_id in efo_ids if efo_id not in pointlessly_small_n_SNPs]\n",
    "\n",
    "efo_ids=efo_ids_not_too_small\n",
    "\n",
    "# Reduce while developing\n",
    "#efo_ids=efo_ids[25:27] # reduced while developing\n",
    "\n",
    "\n",
    "\n",
    "print(n_traits+' traits found. Removed '+str(len(pointlessly_small_n_SNPs))+' traits with fewer than 20 SNPs')\n",
    "\n",
    "SNP_md=pd.DataFrame(md_dict)\n",
    "SNP_md=SNP_md.set_index('efo_id')\n",
    "SNP_md.sort_values('n_SNPs',ascending=False).to_csv(f'/home/jovyan/data/SNPs_md_{today}.csv')\n",
    "SNP_md.sort_values('n_SNPs',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually inspect the output to find traits we do *not* want\n",
    "efo_ids_to_be_removed=['MONDO_0005090','EFO_0004761','EFO_0004286','MONDO_0005277','EFO_0005939','EFO_0004265','EFO_0000712','EFO_0005043','EFO_1001857','EFO_0004791','EFO_0000717','EFO_1001976','EFO_0010071','EFO_0003870','EFO_0009552','EFO_0005524','EFO_1001504','EFO_0004762','EFO_0006501','EFO_0008205','EFO_0004534','EFO_0005128','EFO_0004278','EFO_0004214','EFO_0004517','EFO_0004860','EFO_0006919','EFO_0004644','EFO_0007928','EFO_0010178','EFO_0004578','EFO_1002006','EFO_0006790','EFO_0004520','EFO_0006903','EFO_0000668','MONDO_0016820','MONDO_0010679','MONDO_0001134','EFO_0008204','EFO_0004985','EFO_0004311','EFO_0005529','EFO_0004269','EFO_1000881','EFO_0004277','EFO_0005532','EFO_0005239','EFO_0008373','EFO_0008206','EFO_0006522','EFO_0007787','EFO_1001161','EFO_0005243','EFO_0004507']\n",
    "\n",
    "all_efo_ids=SNP_md.index.tolist()\n",
    "\n",
    "desired_efo_ids=[x for x in all_efo_ids if x not in efo_ids_to_be_removed]\n",
    "\n",
    "SNP_md=SNP_md.loc[desired_efo_ids]\n",
    "\n",
    "n_traits=str(len(SNP_md))\n",
    "print(n_traits+' traits')\n",
    "\n",
    "efo_ids=SNP_md.index.tolist() # defines efo_ids for further analysis\n",
    "\n",
    "SNP_md.sort_values('n_SNPs',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-buffer",
   "metadata": {},
   "source": [
    "# Evaluate whether SNPs are found in peaks using the all_peaks file"
   ]
  },
  {
   "cell_type": "raw",
   "id": "central-panel",
   "metadata": {
    "tags": []
   },
   "source": [
    "# if you need to clear\n",
    "\n",
    "! rm /nfs/team205/heart/EBI_GWAS/SNP_mapped_to_peaks/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-external",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...a SNPs in peaks file for this set of traits is not found, making one now...\n",
      "22:07:57_EFO_0000537:...evaluating for SNPs in peaks...\n",
      "22:08:17_EFO_0000275:...evaluating for SNPs in peaks...\n",
      "22:08:39_MONDO_0005178:...evaluating for SNPs in peaks...\n",
      "22:08:44_EFO_0005763:...evaluating for SNPs in peaks...\n",
      "22:10:04_EFO_0009184:...evaluating for SNPs in peaks...\n",
      "22:10:06_EFO_0004831:...evaluating for SNPs in peaks...\n",
      "22:10:08_EFO_0006919:...evaluating for SNPs in peaks...\n",
      "22:10:10_EFO_0005527:...evaluating for SNPs in peaks...\n",
      "22:10:12_EFO_0004282:...evaluating for SNPs in peaks...\n",
      "22:10:13_EFO_0005524:...evaluating for SNPs in peaks...\n",
      "22:10:18_EFO_0008205:...evaluating for SNPs in peaks...\n",
      "22:10:21_EFO_0003870:...evaluating for SNPs in peaks...\n",
      "22:10:27_EFO_0005055:...evaluating for SNPs in peaks...\n",
      "22:10:42_EFO_0009094:...evaluating for SNPs in peaks...\n",
      "22:10:44_EFO_0008373:...evaluating for SNPs in peaks...\n",
      "22:10:45_MONDO_0005090:...evaluating for SNPs in peaks...\n",
      "22:13:24_EFO_0010071:...evaluating for SNPs in peaks...\n",
      "22:13:30_EFO_1002006:...evaluating for SNPs in peaks...\n",
      "22:13:32_EFO_0001645:...evaluating for SNPs in peaks...\n",
      "22:15:03_EFO_0004327:...evaluating for SNPs in peaks...\n",
      "22:15:24_EFO_0004462:...evaluating for SNPs in peaks...\n",
      "22:15:46_EFO_0000266:...evaluating for SNPs in peaks...\n",
      "22:15:48_EFO_0004762:...evaluating for SNPs in peaks...\n",
      "22:15:51_EFO_0000538:...evaluating for SNPs in peaks...\n",
      "22:15:55_EFO_0005043:...evaluating for SNPs in peaks...\n",
      "22:16:02_EFO_0004761:...evaluating for SNPs in peaks...\n",
      "22:16:33_EFO_0004644:...evaluating for SNPs in peaks...\n",
      "22:16:35_EFO_0004265:...evaluating for SNPs in peaks...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add on a column for each trait, indicating whether a SNP from that trait falls within a peak. This file varies with the which traits are assessed\n",
    "files=os.listdir(snps_path)\n",
    "\n",
    "if os.path.isfile(f'/nfs/team205/heart/EBI_GWAS/SNP_mapped_to_peaks/all_peaks_with_SNPs_for_{n_traits}_traits_incremental.csv')==False:\n",
    "    print(f'...a SNPs in peaks file for this set of traits is NOT found, making one now...')\n",
    "    for efo_id in efo_ids:\n",
    "\n",
    "            file = [f for f in files if f\"{efo_id}\" in f]\n",
    "            file = str(file[0])\n",
    "\n",
    "            snps_df=pd.read_csv(f'{snps_path}{file}')\n",
    "            snps_df=snps_df.set_index('variant_id')\n",
    "\n",
    "            snps_df[\"chrom\"] = snps_df[\"chromosome_name\"].apply(lambda x: 'chr'+str(x)).str.split('.',expand=True)[0] # creates a new 'chrom' column and should work even for X or M chrosomes\n",
    "\n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%H:%M:%S\")\n",
    "            print(f'{current_time}_{efo_id}:...evaluating for SNPs in peaks...')\n",
    "\n",
    "            all_peaks[efo_id]=0\n",
    "            for snp in range(len(snps_df[\"chrom\"])): # This loop incrementally adds 1 if there is a SNP within a peak (open or closed)\n",
    "                all_peaks[efo_id][\n",
    "                    (all_peaks['chrom']==snps_df[\"chrom\"][snp])\n",
    "                    &\n",
    "                    (all_peaks['start'] <= snps_df['chromosome_position'][snp])\n",
    "                    &\n",
    "                    (all_peaks['end'] >= snps_df['chromosome_position'][snp])\n",
    "                ]+=1 # Adds one for each SNP which falls inside a peak\n",
    "    all_peaks.to_csv(f'/nfs/team205/heart/EBI_GWAS/SNP_mapped_to_peaks/all_peaks_with_SNPs_for_{n_traits}_traits_incremental.csv')\n",
    "else:\n",
    "    all_peaks=pd.read_csv(f'/nfs/team205/heart/EBI_GWAS/SNP_mapped_to_peaks/all_peaks_with_SNPs_for_{n_traits}_traits_incremental.csv',index_col='peak')\n",
    "    print(f'...SNPs in peaks file already exists, reading it in...')\n",
    "\n",
    "all_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-curve",
   "metadata": {},
   "source": [
    "# Make a table of peaks x cell for each cell type, binarise using a threshold, then make 1000 permutations, then overwrite the file"
   ]
  },
  {
   "cell_type": "raw",
   "id": "defensive-aquarium",
   "metadata": {
    "tags": []
   },
   "source": [
    "# if you need to clear\n",
    "\n",
    "! rm -r /nfs/team205/heart/EBI_GWAS/binarised_permutation_matrices/*\n",
    "! mkdir /nfs/team205/heart/EBI_GWAS/binarised_permutation_matrices_joined/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# makes cell x peak matrix, including 1000 permutations\n",
    "# NB the SNPs in peaks file needs is specific to the defined set of peaks, which will vary accoring to threshold for binarisation, so this all peaks file needs to be saved according to threshold used\n",
    "\n",
    "permutations=range(n_permutations)\n",
    "\n",
    "bin_mat_path='/nfs/team205/heart/EBI_GWAS/binarised_permutation_matrices/'\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    if os.path.isfile(f'{bin_mat_path}{cell_type}_{n_permutations}_permutations_bin_threshold_{threshold_for_filename}_matrix.csv') == False:\n",
    "\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        print(f'{current_time}...generating binarised matrix for {cell_type}...')\n",
    "\n",
    "        cell_df=pd.DataFrame(peaks.loc[cell_type])\n",
    "        cell_df['peak'] = cell_df.index\n",
    "        cell_df['chrom']=cell_df['peak'].str.split(':',expand=True)[0]\n",
    "        cell_df['peak_window']=cell_df['peak'].str.split(':',expand=True)[1]\n",
    "        cell_df['start']=cell_df['peak_window'].str.split('_',expand=True)[0].astype(int)\n",
    "        cell_df['end']=cell_df['peak_window'].str.split('_',expand=True)[1].astype(int)\n",
    "        cell_df[f'{cell_type}_binarised_real']=cell_df[cell_type].ge(threshold).astype(int)\n",
    "\n",
    "        for permutation in permutations:\n",
    "            cell_df[f'{cell_type}_binarised_permutation_{permutation}'] = np.random.permutation(cell_df[f'{cell_type}_binarised_real'])\n",
    "        cell_df=cell_df.filter(regex=cell_type+'_')\n",
    "        cell_df.to_csv(f'{bin_mat_path}{cell_type}_{n_permutations}_permutations_bin_threshold_{threshold_for_filename}_matrix.csv',index=True)\n",
    "    else:\n",
    "        print(f'NOT generating binarised matrix for {cell_type} since it already exists')\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-graphics",
   "metadata": {},
   "source": [
    "# Read in Binarised Matrix for each cell type, join it to the all_peaks file which has trait info (binding on the index [peaks]), then save these joined binarised matrix files (now with added trait info) in a different directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "joined_bin_mat_path='/nfs/team205/heart/EBI_GWAS/binarised_permutation_matrices_joined_incremental/'\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    if os.path.isfile(f'{joined_bin_mat_path}{cell_type}_{n_permutations}_permutations_bin_threshold_{threshold_for_filename}_matrix_joined.csv') == False:    \n",
    "        \n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(f'{current_time}: {cell_type}: making bin matrix with trait for this cell')\n",
    "\n",
    "        # read in binary matrices which have already been made\n",
    "        binarised_matrix=pd.read_csv(f'{bin_mat_path}{cell_type}_{n_permutations}_permutations_bin_threshold_{threshold_for_filename}_matrix.csv')\n",
    "\n",
    "        # tidy and add the columns we need\n",
    "        binarised_matrix.rename(columns = {'Unnamed: 0':'peak'}, inplace = True)\n",
    "        binarised_matrix=binarised_matrix.set_index(binarised_matrix.iloc[:,0])\n",
    "        binarised_matrix=binarised_matrix.drop(columns=['peak'])\n",
    "        \n",
    "        # add on the columns indicating whether SNPs are in peaks\n",
    "        binarised_matrix=binarised_matrix.join(all_peaks)\n",
    "\n",
    "        # save this modified binary matrix to a separate directory\n",
    "        binarised_matrix.to_csv(f'{joined_bin_mat_path}{cell_type}_{n_permutations}_permutations_bin_threshold_{threshold_for_filename}_matrix_joined.csv')\n",
    "    else:\n",
    "        print(f'file already exists for {cell_type}')\n",
    "\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-leisure",
   "metadata": {},
   "source": [
    "# Calculate enrichment of cell types for different traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While developing\n",
    "efo_ids=efo_ids[2:4]\n",
    "cell_types=cell_types[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Find the proportion of all peaks which are open in this celltype\n",
    "\n",
    "output_path='/nfs/team205/heart/EBI_GWAS/enrichment_output/'\n",
    "\n",
    "list_of_output_dfs=[]\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(f'...================================================================...') \n",
    "print(f'...{current_time}:STARTING')\n",
    "print(f'...================================================================...') \n",
    "\n",
    "# make some empty lists\n",
    "proportion_of_SNPs_found_in_celltype_specific_open_peaks=[]\n",
    "proportion_of_all_open_peaks_found_in_this_celltype=[]\n",
    "proportion_of_SNPs_found_in_permutations_of_celltype_specific_open_peaks=[]\n",
    "proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion=[]\n",
    "n_times_proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion=[]\n",
    "mean_proportions_of_SNPs_in_open_peaks=[]\n",
    "p_values=[]\n",
    "efo_id_list=[]\n",
    "efo_term_list=[]\n",
    "cell_type_list=[]\n",
    "n_SNPs_list=[]\n",
    "\n",
    "permutations=range(n_permutations)\n",
    "\n",
    "print('...evaluating '+str(len(efo_ids))+' traits, across '+str(len(cell_types))+' cell types...')\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(f'...================================================================...')    \n",
    "    print(f'...{current_time}: reading binarised matrix for {cell_type}...')\n",
    "    print(f'...================================================================...') \n",
    "\n",
    "    cell_bin_mat=pd.read_csv(f'{joined_bin_mat_path}{cell_type}_{n_permutations}_permutations_bin_threshold_{threshold_for_filename}_matrix_joined.csv',index_col='peak')\n",
    "    \n",
    "    prop_bins_in_this_cell_type=(len(cell_bin_mat[cell_bin_mat[f'{cell_type}_binarised_real']==1]))/len(cell_bin_mat)\n",
    "            \n",
    "    \n",
    "    for efo_id in efo_ids:\n",
    "                \n",
    "        # grab some metadata\n",
    "        efo_term=SNP_md.loc[efo_id]['efo_term']\n",
    "        n_SNPs=SNP_md.loc[efo_id]['n_SNPs']\n",
    "        \n",
    "        # add columns which won't change until we run a new cell_type\n",
    "        proportion_of_all_open_peaks_found_in_this_celltype.append(prop_bins_in_this_cell_type)\n",
    "        cell_type_list.append(cell_type)\n",
    "\n",
    "        # add columns which won't change until we run a new efo_id\n",
    "        n_SNPs_list.append(n_SNPs)\n",
    "        efo_id_list.append(efo_id)\n",
    "        efo_term_list.append(efo_term)\n",
    "        \n",
    "        # subset to just open regions for this cell type\n",
    "        # find the proportion of SNPs for this trait that lie within this cell types open peaks\n",
    "        observed_proportion=(cell_bin_mat[efo_id][cell_bin_mat[f'{cell_type}_binarised_real']==1].sum())/(cell_bin_mat[efo_id].sum())\n",
    "\n",
    "        proportion_of_SNPs_found_in_celltype_specific_open_peaks.append(observed_proportion)\n",
    "\n",
    "        proportions_of_SNPs_in_open_peaks=[]\n",
    "        \n",
    "\n",
    "        for permutation in permutations:\n",
    "            proportion_of_SNPs_found_in_permutations_of_celltype_specific_open_peaks.append(cell_bin_mat[efo_id][cell_bin_mat[f'{cell_type}_binarised_permutation_{permutation}']==1].sum()/cell_bin_mat[efo_id].sum())\n",
    "\n",
    "        proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion = [i for i in proportion_of_SNPs_found_in_permutations_of_celltype_specific_open_peaks if i >= observed_proportion]\n",
    "        \n",
    "        n_times_proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion.append(len(proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion))\n",
    "\n",
    "        p_values.append(len(proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion)/len(permutations)) # p val is simply the proportion of null hypotheses 'observations' greater than the actual observed proportion\n",
    "\n",
    "        mean_proportions_of_SNPs_in_open_peaks.append(sum(proportion_of_SNPs_found_in_permutations_of_celltype_specific_open_peaks)/len(proportion_of_SNPs_found_in_permutations_of_celltype_specific_open_peaks))\n",
    "        \n",
    "        # Plot histograms for each cell type\n",
    "#        plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "#        plt.rcParams[\"figure.dpi\"] = 300\n",
    "\n",
    "#        plt.hist(proportion_of_SNPs_found_in_permutations_of_celltype_specific_open_peaks,\n",
    "#                 bins=100,color='red',\n",
    "#                 range=(0,1),\n",
    "#                 histtype='stepfilled',edgecolor='none')\n",
    "#        plt.axvline(x=observed_proportion, color='blue', linestyle='--')\n",
    "#        plt.legend(['null: proportion of SNPs falling in randomly shuffled OC regions','observed: proportion of SNPs falling cell-type specific OC regions'])\n",
    "#        plt.title('cell type: '+cell_type+', trait: '+efo_id+', term: '+efo_term+', threshold for binarisation: '+threshold_for_filename)\n",
    "#        plt.savefig(f'{output_path}{efo_id}_{efo_term}_{cell_type}_{threshold_for_filename}_SNP_enrichment.png')\n",
    "#        plt.clf() #clears the current plot\n",
    "\n",
    "        \n",
    "output_dict={\n",
    "    'cell_type':cell_type_list,\n",
    "    'proportion_of_all_open_peaks_found_in_this_celltype':proportion_of_all_open_peaks_found_in_this_celltype,\n",
    "    'proportion_of_SNPs_found_in_celltype_specific_open_peaks':proportion_of_SNPs_found_in_celltype_specific_open_peaks,\n",
    "    'n_times_proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion':n_times_proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion,\n",
    "    'mean_proportions_of_SNPs_in_open_peaks':mean_proportions_of_SNPs_in_open_peaks,\n",
    "    'p_value':p_values,\n",
    "    'n_SNPs':n_SNPs_list,\n",
    "    'efo_id':efo_id_list,\n",
    "    'efo_term':efo_term_list}\n",
    "\n",
    "output_df=pd.DataFrame(output_dict)\n",
    "\n",
    "list_of_output_dfs.append(output_df)\n",
    "combined_output_df=pd.concat(list_of_output_dfs)\n",
    "combined_output_df=combined_output_df.sort_values(by=['efo_id'])\n",
    "combined_output_df=combined_output_df.set_index('cell_type')\n",
    "combined_output_df.to_csv(f'{output_path}{threshold_for_filename}_all_traits_summary.csv')\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(f'...================================================================...')    \n",
    "print(f'...{current_time}:FINSIHED')\n",
    "print(f'...================================================================...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-swedish",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scanpy",
   "language": "python",
   "name": "scanpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
